{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Uninstall existing versions\n",
        "!pip uninstall -y dowhy networkx\n",
        "\n",
        "# Install the latest versions\n",
        "!pip install dowhy networkx\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from dowhy import CausalModel\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "rUd-x9xNn7FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y networkx\n",
        "\n",
        "# 2. Install specific compatible version\n",
        "!pip install networkx==2.8.8\n",
        "\n",
        "# 3. Verify downgrade\n",
        "import networkx as nx\n",
        "print(f\"NetworkX version: {nx.__version__}\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install dowhy\n",
        "from dowhy import CausalModel\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk19fc8KnD6M",
        "outputId": "7e1468a6-f2da-44ed-b57b-fde6e6b219ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: networkx 3.5\n",
            "Uninstalling networkx-3.5:\n",
            "  Successfully uninstalled networkx-3.5\n",
            "Collecting networkx==2.8.8\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: networkx\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "nx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed networkx-2.8.8\n",
            "NetworkX version: 2.8.8\n",
            "Collecting dowhy\n",
            "  Downloading dowhy-0.12-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting causal-learn>=0.1.3.0 (from dowhy)\n",
            "  Downloading causal_learn-0.1.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: cvxpy>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from dowhy) (1.6.6)\n",
            "Collecting cython<3.0 (from dowhy)\n",
            "  Downloading Cython-0.29.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: joblib>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dowhy) (1.5.1)\n",
            "Requirement already satisfied: networkx>=2.8.5 in /usr/local/lib/python3.11/dist-packages (from dowhy) (2.8.8)\n",
            "Requirement already satisfied: numba>=0.59 in /usr/local/lib/python3.11/dist-packages (from dowhy) (0.60.0)\n",
            "Requirement already satisfied: numpy>1.0 in /usr/local/lib/python3.11/dist-packages (from dowhy) (2.0.2)\n",
            "Requirement already satisfied: pandas>1.0 in /usr/local/lib/python3.11/dist-packages (from dowhy) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>1.0 in /usr/local/lib/python3.11/dist-packages (from dowhy) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from dowhy) (1.15.3)\n",
            "Requirement already satisfied: statsmodels>=0.13.5 in /usr/local/lib/python3.11/dist-packages (from dowhy) (0.14.4)\n",
            "Requirement already satisfied: sympy>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from dowhy) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from dowhy) (4.67.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from causal-learn>=0.1.3.0->dowhy) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from causal-learn>=0.1.3.0->dowhy) (3.10.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (from causal-learn>=0.1.3.0->dowhy) (3.0.4)\n",
            "Collecting momentchi2 (from causal-learn>=0.1.3.0->dowhy)\n",
            "  Downloading momentchi2-0.1.8-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.2.2->dowhy) (1.0.4)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.2.2->dowhy) (0.11.1)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.2.2->dowhy) (3.2.7.post2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.59->dowhy) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>1.0->dowhy) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>1.0->dowhy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>1.0->dowhy) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>1.0->dowhy) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.5->dowhy) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.5->dowhy) (24.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.10.1->dowhy) (1.3.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.11/dist-packages (from clarabel>=0.5.0->cvxpy>=1.2.2->dowhy) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.2.2->dowhy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.2.2->dowhy) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>1.0->dowhy) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (3.2.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi->clarabel>=0.5.0->cvxpy>=1.2.2->dowhy) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->osqp>=0.6.2->cvxpy>=1.2.2->dowhy) (3.0.2)\n",
            "Downloading dowhy-0.12-py3-none-any.whl (398 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.4/398.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading causal_learn-0.1.4.3-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.0/193.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Cython-0.29.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading momentchi2-0.1.8-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: cython, momentchi2, causal-learn, dowhy\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 3.0.12\n",
            "    Uninstalling Cython-3.0.12:\n",
            "      Successfully uninstalled Cython-3.0.12\n",
            "Successfully installed causal-learn-0.1.4.3 cython-0.29.37 dowhy-0.12 momentchi2-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the Causal Graph\n",
        "# The graph is defined by listing the edges (parent, child)\n",
        "# Based on the provided DAG image and OCR\n",
        "causal_graph_edges = [\n",
        "    ('REC_AGE', 'OPEN'),\n",
        "    ('ROUTES_RUN', 'OPEN'),\n",
        "    ('ROUTES_RUN', 'TARGETS'),\n",
        "    ('OPEN', 'TARGETS'),\n",
        "    ('ROUTES_RUN', 'FIRST_READ'),\n",
        "    ('FIRST_READ', 'TARGETS'),\n",
        "    ('O_LINE', 'PASS_BLK'),\n",
        "    ('O_LINE', 'RUN_BLK'),\n",
        "    ('O_LINE', 'OFFENSE'),\n",
        "    ('PASS_BLK', 'QB'),\n",
        "    ('PASS_BLK', 'ADOT'),\n",
        "    ('QB', 'PASS_ATT'),\n",
        "    ('QB', 'OFFENSE'),\n",
        "    ('QB', 'TARGETS'),\n",
        "    ('QB', 'ADOT'),\n",
        "    ('PASS_ATT', 'PASS_YDS'),\n",
        "    ('PASS_ATT', 'PASS_TDS'),\n",
        "    ('PASS_ATT', 'ROUTES_RUN'),\n",
        "    ('OFFENSE', 'SCORE_DIFF'),\n",
        "    ('DEFENSE', 'SCORE_DIFF'),\n",
        "    ('ST', 'SCORE_DIFF'),\n",
        "    ('SCORE_DIFF', 'PASS_ATT'),\n",
        "    ('SCORE_DIFF', 'RUSH_ATT'),\n",
        "    ('TARGETS', 'REC'),\n",
        "    ('TARGETS', 'ADOT'),\n",
        "    ('REC', 'REC_YDS'),\n",
        "    ('REC', 'REC_TDS'),\n",
        "    ('REC', 'WR/TE_FPTS'),\n",
        "    ('REC', 'RB_FPTS'),\n",
        "    ('REC_YDS', 'WR/TE_FPTS'),\n",
        "    ('REC_TDS', 'WR/TE_FPTS'),\n",
        "    ('REC_YDS', 'RB_FPTS'),\n",
        "    ('REC_TDS', 'RB_FPTS'),\n",
        "    ('ADOT', 'REC_YDS'),\n",
        "    ('RUSH_AGE', 'YPC'),\n",
        "    ('YPC', 'RUSH_ATT'),\n",
        "    ('RUN_BLK', 'RUSH_ATT'),\n",
        "    ('RUN_BLK', 'YPC'),\n",
        "    ('RUSH_ATT', 'RUSH_YDS'),\n",
        "    ('RUSH_ATT', 'RUSH_TDS'),\n",
        "    ('RUSH_YDS', 'RB_FPTS'),\n",
        "    ('RUSH_TDS', 'RB_FPTS'),\n",
        "    ('RUSH_YDS', 'WR/TE_FPTS'),\n",
        "    ('RUSH_TDS', 'WR/TE_FPTS'),\n",
        "    ('RUSH_YDS', 'QB_FPTS'),\n",
        "    ('RUSH_TDS', 'QB_FPTS'),\n",
        "    ('PASS_YDS', 'QB_FPTS'),\n",
        "    ('PASS_TDS', 'QB_FPTS')\n",
        "]\n",
        "\n",
        "# Create a NetworkX DiGraph\n",
        "G = nx.DiGraph(causal_graph_edges)"
      ],
      "metadata": {
        "id": "g16pGRLt87-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Generate Synthetic Data\n",
        "def generate_synthetic_data(num_samples=1000):\n",
        "    np.random.seed(27) # for reproducibility\n",
        "    data = pd.DataFrame()\n",
        "\n",
        "    # Root nodes (no parents)\n",
        "    data['REC_AGE'] = np.clip(np.random.normal(25, 3, num_samples), 21, None) # Reciever age - can't be below 21\n",
        "    #data['ROUTES_RUN'] = np.random.normal(300, 50, num_samples) # Routes run per season\n",
        "    data['O_LINE'] = np.random.normal(75, 10, num_samples) # Offensive line quality (e.g., PFF grade)\n",
        "    #data['FIRST_READ'] = np.random.normal(0.6, 0.1, num_samples) # QB's tendency to target first read\n",
        "    data['RUSH_AGE'] = np.clip(np.random.normal(24, 2, num_samples), 21, None) # RB age\n",
        "    #data['OFFENSE'] = np.random.normal(25, 5, num_samples) # Offensive efficiency score\n",
        "    data['DEFENSE'] = np.random.normal(20, 5, num_samples) # Defensive efficiency score\n",
        "    data['ST'] = np.random.normal(5, 2, num_samples) # Special Teams contribution\n",
        "\n",
        "    # Blocking\n",
        "    data['PASS_BLK'] = 0.85 * data['O_LINE'] + np.random.normal(0, 5, num_samples) # Pass blocking quality - mostly completely dependent on oline - maybe some on RB/TE but that is neg;ible\n",
        "    data['RUN_BLK'] = 0.7 * data['O_LINE'] + np.random.normal(0, 5, num_samples) # Run blocking quality - also semi dependent on TE and WR\n",
        "\n",
        "    #QB, Offense, and DIFF\n",
        "    data['QB'] = 0.1 * data['O_LINE'] + 0.2 * data['PASS_BLK'] + np.random.normal(0, 10, num_samples) # QB quality/performance\n",
        "    data['OFFENSE'] = 0.7 * data['QB'] + 0.1 * data['O_LINE'] + np.random.normal(25, 5, num_samples) # Offensive efficiency score\n",
        "    data['SCORE_DIFF'] = 0.6 * data['OFFENSE'] - 0.5 * data['DEFENSE'] + 0.2 * data['ST'] + np.random.normal(0, 7, num_samples) # Game score differential\n",
        "\n",
        "    #Everything Targets\n",
        "    data['PASS_ATT'] = 0.6 * data['QB'] + 0.3 * data['SCORE_DIFF'] + np.random.normal(0, 15, num_samples) # Pass attempts\n",
        "    data['ROUTES_RUN'] = 0.7 * data['PASS_ATT'] +  np.random.normal(300, 50, num_samples) # Routes run per season\n",
        "    data['OPEN'] = 0.3 * data['REC_AGE'] + 0.3 * data['ROUTES_RUN'] + np.random.normal(0, 5, num_samples) # Player's ability to get open\n",
        "    data['FIRST_READ'] = 0.2 * data['ROUTES_RUN'] + np.random.normal(0.6, 0.1, num_samples) # first reads get targetted more\n",
        "    data['TARGETS'] = 0.2 * data['ROUTES_RUN'] + 0.3 * data['OPEN'] + 0.2 * data['FIRST_READ'] + 0.2 * data['QB'] + np.random.normal(0, 20, num_samples) # Player targets\n",
        "    data['REC'] = 0.7 * data['TARGETS'] + np.random.normal(0, 10, num_samples) # Receptions\n",
        "    data['ADOT'] = 0.3 * data['TARGETS'] + 0.3 * data['QB'] + 0.3 * data['PASS_BLK'] + np.random.normal(0, 2, num_samples) # Average Depth of Target\n",
        "\n",
        "    # Performance metrics\n",
        "    data['REC_YDS'] = 0.9 * data['REC'] + 0.5 * data['ADOT'] + np.random.normal(0, 20, num_samples) # Receiving Yards\n",
        "    data['REC_TDS'] = 0.1 * data['REC'] + 0.05 * data['REC_YDS'] + np.random.normal(0, 1, num_samples) # Receiving Touchdowns\n",
        "\n",
        "    #Rushing\n",
        "    data['YPC'] = 0.7 * data['RUSH_AGE'] + 0.5 * data['RUN_BLK'] + np.random.normal(0, 1.5, num_samples) # Yards per carry (influenced by age)\n",
        "    data['RUSH_ATT'] = 0.5 * data['YPC'] + 0.4 * data['RUN_BLK'] - 0.2 * data['SCORE_DIFF'] + np.random.normal(0, 10, num_samples) # Rush attempts\n",
        "\n",
        "    # Performance metrics\n",
        "    data['RUSH_YDS'] = 0.8 * data['RUSH_ATT'] + 0.6 * data['YPC'] + np.random.normal(0, 25, num_samples) # Rushing Yards\n",
        "    data['RUSH_TDS'] = 0.1 * data['RUSH_ATT'] + 0.05 * data['RUSH_YDS'] + np.random.normal(0, 1, num_samples) # Rushing Touchdowns\n",
        "\n",
        "\n",
        "    #data['PASS_YDS'] = 0.9 * data['PASS_ATT'] + 0.7 * data['QB'] + np.random.normal(0, 50, num_samples) # Passing Yards\n",
        "    #data['PASS_TDS'] = 0.1 * data['PASS_ATT'] + 0.05 * data['PASS_YDS'] + np.random.normal(0, 2, num_samples) # Passing Touchdowns\n",
        "\n",
        "    data['PASS_YDS'] = 0.9 * data['PASS_ATT'] + np.random.normal(0, 50, num_samples) # Passing Yards\n",
        "    data['PASS_TDS'] = 0.1 * data['PASS_ATT'] + np.random.normal(0, 2, num_samples) # Passing Touchdowns\n",
        "\n",
        "    # Fantasy Points (Outcomes)\n",
        "    # Standard scoring: 1 point per 10 receiving/rushing yards, 6 points per receiving/rushing TD, 4 points per passing TD, 1 point per 25 passing yards\n",
        "    data['WR/TE_FPTS'] = (data['REC_YDS'] / 10) + (data['REC_TDS'] * 6) + (data['REC'] * 1) # Assuming 0.5 PPR\n",
        "    data['RB_FPTS'] = (data['RUSH_YDS'] / 10) + (data['RUSH_TDS'] * 6) + (data['REC'] * 1) + (data['REC_YDS'] / 10) + (data['REC_TDS'] * 6) # RBs also get receiving points\n",
        "    data['QB_FPTS'] = (data['PASS_YDS'] / 25) + (data['PASS_TDS'] * 4) + (data['RUSH_YDS'] / 10) + (data['RUSH_TDS'] * 6)# QBs also get rushing points\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "A96dkvVl9Agh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sample data\n",
        "sample_data = generate_synthetic_data(num_samples=1000)\n",
        "print(\"Sample Data Head:\")\n",
        "print(sample_data.head())\n",
        "print(\"\\nSample Data Description:\")\n",
        "print(sample_data.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeNZmFPd9FZ-",
        "outputId": "d6d3abdc-c873-4de7-ba11-4670d2464c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Data Head:\n",
            "     REC_AGE     O_LINE   RUSH_AGE    DEFENSE        ST   PASS_BLK    RUN_BLK  \\\n",
            "0  28.856816  76.027941  22.807111  20.806464  4.831909  64.599976  53.133688   \n",
            "1  24.089340  85.709214  25.558958  23.500955  7.483635  72.495699  57.130675   \n",
            "2  26.857227  75.503634  23.264869  15.294023  6.200368  69.183960  62.180602   \n",
            "3  26.187996  83.498318  24.964485  15.145495  6.430333  74.448858  56.041106   \n",
            "4  25.670217  80.425170  24.246238  20.562220  4.270015  63.216158  49.564386   \n",
            "\n",
            "          QB    OFFENSE  SCORE_DIFF  ...    REC_TDS        YPC   RUSH_ATT  \\\n",
            "0  35.899655  54.970145   14.017904  ...   8.945955  43.452788  43.785197   \n",
            "1  25.141855  43.566063    8.470577  ...  10.647949  45.096587  40.236296   \n",
            "2  18.232314  49.453363   25.568432  ...  13.218998  48.253737  47.662130   \n",
            "3  29.008834  51.937236   34.503491  ...  14.016065  46.733464  63.729032   \n",
            "4  10.743446  40.656442   10.257548  ...  11.528714  41.326856  45.627809   \n",
            "\n",
            "    RUSH_YDS   RUSH_TDS   PASS_YDS  PASS_TDS  WR/TE_FPTS     RB_FPTS  \\\n",
            "0  79.213683   9.007740  16.521758  3.355880  118.082610  180.050415   \n",
            "1  91.081555   8.874878 -33.473768  2.558943  126.236919  188.594340   \n",
            "2  59.785025   7.329589  41.748198  2.125262  180.207235  230.163269   \n",
            "3  54.554363  11.091837  62.851803 -1.118029  171.915417  243.921873   \n",
            "4  49.824506   8.154580  66.260986 -1.982113  138.295421  192.205350   \n",
            "\n",
            "     QB_FPTS  \n",
            "0  76.052196  \n",
            "1  71.254241  \n",
            "2  60.127010  \n",
            "3  70.048413  \n",
            "4  48.631917  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "\n",
            "Sample Data Description:\n",
            "           REC_AGE       O_LINE     RUSH_AGE      DEFENSE           ST  \\\n",
            "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
            "mean     25.111451    75.357657    24.089469    19.877672     5.010474   \n",
            "std       2.846390     9.428842     1.862355     5.107671     1.950060   \n",
            "min      21.000000    42.869308    21.000000     5.466288    -1.052541   \n",
            "25%      22.854541    69.023450    22.711754    16.294531     3.639741   \n",
            "50%      24.984036    75.490754    24.043540    19.644404     4.976715   \n",
            "75%      26.988892    81.301111    25.316642    23.358721     6.209907   \n",
            "max      34.530519   104.906437    29.402724    34.365617    12.008176   \n",
            "\n",
            "          PASS_BLK      RUN_BLK           QB      OFFENSE   SCORE_DIFF  ...  \\\n",
            "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  ...   \n",
            "mean     64.003335    52.620368    20.332780    46.748865    19.046342  ...   \n",
            "std       9.468200     8.321868     9.963204     8.878141     9.120280  ...   \n",
            "min      28.062125    24.866648   -15.137993    18.116909   -12.283957  ...   \n",
            "25%      57.980532    47.001968    13.498492    40.737489    12.878654  ...   \n",
            "50%      63.973012    52.691341    20.154208    46.546024    19.367982  ...   \n",
            "75%      70.209339    58.478625    27.126831    53.245117    25.218874  ...   \n",
            "max      94.910153    77.093961    52.400861    78.553858    47.012017  ...   \n",
            "\n",
            "           REC_TDS          YPC     RUSH_ATT     RUSH_YDS     RUSH_TDS  \\\n",
            "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
            "mean     12.608614    43.165178    39.262424    57.387026     6.847826   \n",
            "std       3.758896     4.543736    11.303633    27.546713     2.301498   \n",
            "min       1.664792    28.074534     3.952585   -31.182289    -1.069502   \n",
            "25%      10.072303    40.069177    32.069286    38.125483     5.287960   \n",
            "50%      12.698852    43.063446    39.255772    57.400437     6.835388   \n",
            "75%      15.152802    46.460500    46.722535    76.914636     8.375905   \n",
            "max      26.693146    57.771092    78.826036   138.452728    14.356146   \n",
            "\n",
            "          PASS_YDS     PASS_TDS   WR/TE_FPTS      RB_FPTS      QB_FPTS  \n",
            "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
            "mean     13.561524     1.771552   162.510282   209.335943    54.454329  \n",
            "std      53.134879     2.556132    46.343396    49.819223    19.293716  \n",
            "min    -143.854570    -6.424905    24.589789    52.261335    -2.994976  \n",
            "25%     -21.825426     0.078979   131.088501   175.689638    42.296718  \n",
            "50%      12.668087     1.767514   162.114896   208.991023    55.047514  \n",
            "75%      48.472369     3.529891   193.509348   242.726881    68.193438  \n",
            "max     185.444154     9.846882   320.587347   357.599418   106.209850  \n",
            "\n",
            "[8 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Causal Effect Estimation for WR/TE_FPTS\n",
        "# Let's estimate the causal effect of 'TARGETS' on 'WR/TE_FPTS'\n",
        "\n",
        "# Convert graph to DOT format for DoWhy\n",
        "dot_graph = 'digraph {'\n",
        "for u, v in G.edges():\n",
        "    dot_graph += f'\"{u}\" -> \"{v}\";'\n",
        "dot_graph += '}'\n",
        "\n",
        "# Initialize the CausalModel\n",
        "model_wr_te = CausalModel(\n",
        "    data=sample_data,\n",
        "    graph=dot_graph,\n",
        "    treatment='TARGETS',\n",
        "    outcome='WR/TE_FPTS'\n",
        ")\n",
        "\n",
        "# Identify the causal estimand\n",
        "identified_estimand_wr_te = model_wr_te.identify_effect(proceed_when_unidentifiable=True)\n",
        "print(\"\\nIdentified Estimand for TARGETS -> WR/TE_FPTS:\")\n",
        "print(identified_estimand_wr_te)\n",
        "\n",
        "# Estimate the causal effect using a linear regression estimator\n",
        "# We'll use the 'backdoor' criterion which is common for DAGs\n",
        "causal_estimate_wr_te = model_wr_te.estimate_effect(\n",
        "    identified_estimand_wr_te,\n",
        "    method_name=\"backdoor.linear_regression\",\n",
        "    control_value=sample_data['TARGETS'].min(),\n",
        "    treatment_value=sample_data['TARGETS'].max()\n",
        ")\n",
        "print(\"\\nCausal Estimate (TARGETS on WR/TE_FPTS):\")\n",
        "print(causal_estimate_wr_te)\n",
        "print(f\"Estimated Causal Effect (ATE): {causal_estimate_wr_te.value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1UeWBKz9Iay",
        "outputId": "9b8001c1-f55c-40ff-f0dd-a6052f456eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:dowhy.causal_graph:Error: Pygraphviz cannot be loaded. No module named 'pygraphviz'\n",
            "Trying pydot ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Identified Estimand for TARGETS -> WR/TE_FPTS:\n",
            "Estimand type: EstimandType.NONPARAMETRIC_ATE\n",
            "\n",
            "### Estimand : 1\n",
            "Estimand name: backdoor\n",
            "Estimand expression:\n",
            "    d                                  \n",
            "──────────(E[WR/TE_FPTS|QB,SCORE_DIFF])\n",
            "d[TARGETS]                             \n",
            "Estimand assumption 1, Unconfoundedness: If U→{TARGETS} and U→WR/TE_FPTS then P(WR/TE_FPTS|TARGETS,QB,SCORE_DIFF,U) = P(WR/TE_FPTS|TARGETS,QB,SCORE_DIFF)\n",
            "\n",
            "### Estimand : 2\n",
            "Estimand name: iv\n",
            "No such variable(s) found!\n",
            "\n",
            "### Estimand : 3\n",
            "Estimand name: frontdoor\n",
            "No such variable(s) found!\n",
            "\n",
            "\n",
            "Causal Estimate (TARGETS on WR/TE_FPTS):\n",
            "*** Causal Estimate ***\n",
            "\n",
            "## Identified estimand\n",
            "Estimand type: EstimandType.NONPARAMETRIC_ATE\n",
            "\n",
            "### Estimand : 1\n",
            "Estimand name: backdoor\n",
            "Estimand expression:\n",
            "    d                                  \n",
            "──────────(E[WR/TE_FPTS|QB,SCORE_DIFF])\n",
            "d[TARGETS]                             \n",
            "Estimand assumption 1, Unconfoundedness: If U→{TARGETS} and U→WR/TE_FPTS then P(WR/TE_FPTS|TARGETS,QB,SCORE_DIFF,U) = P(WR/TE_FPTS|TARGETS,QB,SCORE_DIFF)\n",
            "\n",
            "## Realized estimand\n",
            "b: WR/TE_FPTS~TARGETS+QB+SCORE_DIFF+TARGETS*RUN_BLK+TARGETS*RUSH_TDS+TARGETS*YPC+TARGETS*RUSH_ATT+TARGETS*RUSH_YDS+TARGETS*RUSH_AGE\n",
            "Target units: \n",
            "\n",
            "## Estimate\n",
            "Mean value: 255.43078103563735\n",
            "### Conditional Estimates\n",
            "__categorical__RUN_BLK  __categorical__RUSH_TDS  __categorical__YPC            __categorical__RUSH_ATT  __categorical__RUSH_YDS  __categorical__RUSH_AGE\n",
            "(24.866, 45.613]        (-1.071, 4.959]          (28.073999999999998, 39.349]  (3.952, 30.115]          (-31.183, 33.787]        (20.999, 22.354]           1.465251\n",
            "                                                                                                                                 (22.354, 23.621]           1.475531\n",
            "                                                                                                                                 (23.621, 24.506]           1.475268\n",
            "                                                                                                                                 (24.506, 25.633]           1.488925\n",
            "                                                                                                                                 (25.633, 29.403]           1.488091\n",
            "                                                                                                                                                              ...   \n",
            "(59.79, 77.094]         (8.725, 14.356]          (47.127, 57.771]              (48.379, 78.826]         (81.459, 138.453]        (20.999, 22.354]           1.493990\n",
            "                                                                                                                                 (22.354, 23.621]           1.497685\n",
            "                                                                                                                                 (23.621, 24.506]           1.499449\n",
            "                                                                                                                                 (24.506, 25.633]           1.502402\n",
            "                                                                                                                                 (25.633, 29.403]           1.512932\n",
            "Length: 810, dtype: float64\n",
            "Estimated Causal Effect (ATE): 255.43078103563735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Prediction with Causal Insights\n",
        "# To predict the actual fantasy points, we can train a predictive model\n",
        "# using the variables that causally influence the outcome.\n",
        "# For WR/TE_FPTS, key causal factors from the DAG include REC_YDS, REC_TDS, REC, ADOT, TARGETS, etc.\n",
        "# We'll use a simple linear regression model for demonstration.\n",
        "\n",
        "# Define features for WR/TE_FPTS prediction based on the DAG's direct and indirect influences\n",
        "# We'll pick some variables that are upstream or directly influence WR/TE_FPTS\n",
        "\n",
        "#features_wr_te = ['REC_YDS', 'REC_TDS', 'REC', 'TARGETS', 'ADOT', 'REC_AGE', 'ROUTES_RUN', 'OPEN', 'FIRST_READ']\n",
        "\n",
        "features_wr_te = ['TARGETS', 'ADOT', 'REC_AGE', 'ROUTES_RUN', 'OPEN', 'FIRST_READ']\n",
        "target_wr_te = 'WR/TE_FPTS'\n",
        "\n",
        "# Prepare data for prediction model\n",
        "X_wr_te = sample_data[features_wr_te]\n",
        "y_wr_te = sample_data[target_wr_te]\n",
        "\n",
        "# Add a constant for the intercept in statsmodels\n",
        "X_wr_te = sm.add_constant(X_wr_te)\n",
        "\n",
        "# Train the linear regression model\n",
        "prediction_model_wr_te = sm.OLS(y_wr_te, X_wr_te).fit()\n",
        "print(\"\\nPrediction Model Summary (WR/TE_FPTS):\")\n",
        "print(prediction_model_wr_te.summary())\n",
        "\n",
        "sample_player_data_raw = pd.DataFrame({\n",
        "    'TARGETS': [100],\n",
        "    'ADOT': [10.5],\n",
        "    'REC_AGE': [26],\n",
        "    'ROUTES_RUN': [450],\n",
        "    'OPEN': [200],\n",
        "    'FIRST_READ': [50]\n",
        "})\n",
        "\n",
        "'''\n",
        "# Demo prediction with sample data\n",
        "sample_player_data_raw = pd.DataFrame({\n",
        "    'REC_YDS': [1000],\n",
        "    'REC_TDS': [8],\n",
        "    'REC': [70],\n",
        "    'TARGETS': [100],\n",
        "    'ADOT': [10.5],\n",
        "    'REC_AGE': [26],\n",
        "    'ROUTES_RUN': [450],\n",
        "    'OPEN': [70],\n",
        "    'FIRST_READ': [0.55]\n",
        "})\n",
        "\n",
        "\n",
        "sample_player_data = sm.add_constant(sample_player_data)\n",
        "\n",
        "predicted_fpts = prediction_model_wr_te.predict(sample_player_data)\n",
        "print(f\"\\nPredicted WR/TE_FPTS for sample player: {predicted_fpts[0]:.2f}\")\n",
        "'''\n",
        "\n",
        "# Select the features for prediction data\n",
        "sample_player_data = sample_player_data_raw[features_wr_te]\n",
        "\n",
        "# Add the constant column explicitly, ensuring it's of the correct type (usually float)\n",
        "sample_player_data['const'] = 1.0\n",
        "\n",
        "# Reorder the columns to match the training data (X_wr_te)\n",
        "sample_player_data_final = sample_player_data[X_wr_te.columns]\n",
        "\n",
        "# Now predict using the correctly formatted data\n",
        "predicted_fpts = prediction_model_wr_te.predict(sample_player_data_final)\n",
        "print(f\"\\nPredicted WR/TE_FPTS for sample player: {predicted_fpts[0]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGljaZ229MRs",
        "outputId": "c11983ce-91ca-4287-cc25-010ac521493a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction Model Summary (WR/TE_FPTS):\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:             WR/TE_FPTS   R-squared:                       0.778\n",
            "Model:                            OLS   Adj. R-squared:                  0.777\n",
            "Method:                 Least Squares   F-statistic:                     579.7\n",
            "Date:                Tue, 24 Jun 2025   Prob (F-statistic):          2.69e-320\n",
            "Time:                        15:41:28   Log-Likelihood:                -4502.2\n",
            "No. Observations:                1000   AIC:                             9018.\n",
            "Df Residuals:                     993   BIC:                             9053.\n",
            "Df Model:                           6                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -6.7288      8.772     -0.767      0.443     -23.942      10.485\n",
            "TARGETS        1.5449      0.058     26.649      0.000       1.431       1.659\n",
            "ADOT          -0.0709      0.139     -0.510      0.610      -0.344       0.202\n",
            "REC_AGE        0.3835      0.251      1.530      0.126      -0.108       0.875\n",
            "ROUTES_RUN    -0.9678      1.371     -0.706      0.480      -3.658       1.722\n",
            "OPEN           0.0679      0.137      0.494      0.621      -0.202       0.338\n",
            "FIRST_READ     4.5794      6.846      0.669      0.504      -8.855      18.014\n",
            "==============================================================================\n",
            "Omnibus:                        1.585   Durbin-Watson:                   1.983\n",
            "Prob(Omnibus):                  0.453   Jarque-Bera (JB):                1.484\n",
            "Skew:                           0.044   Prob(JB):                        0.476\n",
            "Kurtosis:                       3.167   Cond. No.                     5.04e+03\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 5.04e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "\n",
            "Predicted WR/TE_FPTS for sample player: -35.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxv8-ubh8xaJ"
      },
      "outputs": [],
      "source": [
        "# How to use with real-world data:\n",
        "# 1. Load your real-world data into a pandas DataFrame.\n",
        "#    Example: real_data = pd.read_csv('your_fantasy_data.csv')\n",
        "# 2. Ensure your column names match the nodes in the DAG (e.g., 'REC_AGE', 'TARGETS', 'WR/TE_FPTS').\n",
        "# 3. You can then use the trained `prediction_model_wr_te` (or similar models for RB/QB)\n",
        "#    to predict fantasy points for new players, ensuring their data has the same features.\n",
        "#    Example: new_player_real_data = pd.DataFrame(...)\n",
        "#             new_player_real_data = sm.add_constant(new_player_real_data[features_wr_te])\n",
        "#             real_predicted_fpts = prediction_model_wr_te.predict(new_player_real_data)\n",
        "\n",
        "# Example for RB_FPTS prediction\n",
        "features_rb = ['RUSH_YDS', 'RUSH_TDS', 'RUSH_ATT', 'YPC', 'RUN_BLK', 'RUSH_AGE', 'REC', 'REC_YDS', 'REC_TDS'] # Including receiving for RBs\n",
        "target_rb = 'RB_FPTS'\n",
        "X_rb = sample_data[features_rb]\n",
        "y_rb = sample_data[target_rb]\n",
        "X_rb = sm.add_constant(X_rb)\n",
        "prediction_model_rb = sm.OLS(y_rb, X_rb).fit()\n",
        "print(\"\\nPrediction Model Summary (RB_FPTS):\")\n",
        "print(prediction_model_rb.summary())\n",
        "\n",
        "# Example for QB_FPTS prediction\n",
        "features_qb = ['PASS_YDS', 'PASS_TDS', 'PASS_ATT', 'QB', 'RUSH_YDS', 'RUSH_TDS'] # Including rushing for QBs\n",
        "target_qb = 'QB_FPTS'\n",
        "X_qb = sample_data[features_qb]\n",
        "y_qb = sample_data[target_qb]\n",
        "X_qb = sm.add_constant(X_qb)\n",
        "prediction_model_qb = sm.OLS(y_qb, X_qb).fit()\n",
        "print(\"\\nPrediction Model Summary (QB_FPTS):\")\n",
        "print(prediction_model_qb.summary())\n"
      ]
    }
  ]
}